<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Face detection</title>
    <style>
        video {
            position: absolute;
            top: 0;
            left: 0;
            z-index: -1;
            /* Mirror the local sourceVideo */
            transform: scale(-1, 1);            /*For Firefox (& IE) */
            -webkit-transform: scale(-1, 1);     /*for Chrome & Opera (& Safari) */
            height: 480px;
            width: 640px;
        }
        canvas{
            display: none;
            position: absolute;
            top: 0;
            left: 0;
            z-index:0
        }
        button#start{
            font-size: x-large;
            padding: 5px;
            margin: 10px 200px auto;
            align-self: center;

        }
    </style>
    <!-- Load TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.2"></script>
    <!-- Load BodyPix -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.0"></script>
    <!-- Load jQuery -->
    <script src="https://code.jquery.com/jquery-3.5.1.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
</head>

<body>
<div id="main">
    <canvas></canvas>
    <video id="myVid" autoplay playsinline></video>
    <button id="start">Start monitoring</button>
</div>

<script>
const videoWidth = 640;
const videoHeight = 480;
// element selectors
const sourceVideo = document.querySelector('video');
const drawCanvas = document.querySelector('canvas');

// Get video camera
function handleSuccess(stream) {
    const video = document.querySelector('video');
    console.log(`Using video device: ${stream.getVideoTracks()[0].label}`);
    video.srcObject = stream;
}

function handleError(error) {
    if (error.name === 'ConstraintNotSatisfiedError') {
        console.error(`The resolution requested is not supported by your device.`);
    } else if (error.name === 'PermissionDeniedError') {
        console.error("User denied access to media devices");
    }
    console.error(`getUserMedia error: ${error.name}`, error);
}

document.querySelector('#main').addEventListener('click', e => {
    navigator.mediaDevices.getUserMedia({video: {width: videoWidth, height: videoHeight}})
        .then(handleSuccess)
        .catch(handleError)
});


const saveFaceImages = true;
// Canvas setup
const drawCtx = drawCanvas.getContext('2d');
var img_counter = 0;

// Global flags
const flipHorizontal = true;
let stopPrediction = false;
let isPlaying = false,
    gotMetadata = false;
let firstRun = true;

// check if metadata is ready - we need the sourceVideo size
sourceVideo.onloadedmetadata = () => {
    console.log("video metadata ready");
    gotMetadata = true;
    if (isPlaying)
        load()
};

// Check if the sourceVideo has started playing
sourceVideo.onplaying = () => {
    console.log("video playing");
    isPlaying = true;
    if (gotMetadata)
        load()
};

function load(multiplier=0.75, stride=16) {
    sourceVideo.width = sourceVideo.videoWidth;
    sourceVideo.height = sourceVideo.videoHeight;

    // Canvas results for displaying masks
    drawCanvas.width = sourceVideo.videoWidth;
    drawCanvas.height = sourceVideo.videoHeight;

    bodyPix.load({multiplier: multiplier, stride: stride, quantBytes: 4})
        .then(net => predictLoop(net))
        .catch(err => console.error(err));
}

async function predictLoop(net) {
    stopPrediction = false;

    let lastFaceArray = new Int32Array(sourceVideo.width * sourceVideo.height);
    let alerts = 0;
    let alertTimeout = false;

    drawCanvas.style.display = "block";

    // Timer to update the face mask
    let updateFace = true;
    setInterval(() => {
        updateFace = !updateFace;
    }, 1000);

    while (isPlaying && !stopPrediction) {
        // BodyPix setup
        const segmentPersonConfig = {
            flipHorizontal: flipHorizontal,     // Flip for webcam
            maxDetections: 1,                   // only look at one person in this model
            scoreThreshold: 0.5,
            segmentationThreshold: 0.6,         // default is 0.7
        };
        const segmentation = await net.segmentPersonParts(sourceVideo, segmentPersonConfig);


        const faceThreshold = 0.9;
        const touchThreshold = 0.01;

        const numPixels = segmentation.width * segmentation.height;


        // skip if noting is there
        if (segmentation.allPoses[0] === undefined) {
            // console.info("No segmentation data");
            continue;
        }

        // Draw faceborder to canvas
        draw(segmentation);        
    }

}

// Use the bodyPix draw API's
function draw(personSegmentation) {
    let targetSegmentation = personSegmentation;

    // Just show the face
    targetSegmentation.data = personSegmentation.data.map(val => {
        if (val !== 0 && val !== 1)
            return -1;
        else
            return val;
    });

    const coloredPartImage = bodyPix.toColoredPartMask(targetSegmentation);
    const opacity = 0;
    const maskBlurAmount = 0;
    bodyPix.drawMask(
        drawCanvas, sourceVideo, coloredPartImage, opacity, maskBlurAmount,
        flipHorizontal);

    img_counter++;
    if (saveFaceImages && img_counter % 1 == 0) {
        pixels = targetSegmentation.data;

        var left_x = -1,
            right_x = videoWidth,
            top_y = videoHeight,
            bottom_y = -1;

        for (var y = 0; y < videoHeight; y++) {
            for (var x = 0; x < videoWidth; x++) {
                val = pixels[x + y * videoWidth];

                // nothing found
                if (val != 0 && val != 1)
                    continue

                // left border
                if (left_x < x)
                    left_x = x
                // right border
                if (right_x > x)
                    right_x = x
                // top border (first face pixel is top pixel)
                if (top_y > y)
                    top_y = y
                // bottom border
                if (bottom_y < y)
                    bottom_y = y
            }
        }

        $.ajax({
            url: '/',
            type: 'POST',
            contentType: 'application/json',
            dataType: 'json',
            data: JSON.stringify({
                name: img_counter.toString() + '_' + Date.now().toString(),
                img: drawCanvas.toDataURL(),
                top: top_y,
                left: 640 - left_x,
                height: bottom_y - top_y,
                width: (640 - right_x) - (640 - left_x)
            }),
        });
    }

}

</script>

</body>
</html>
